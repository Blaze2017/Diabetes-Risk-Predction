{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing\n",
    "## Define the input and output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_HORIZON = 20\n",
    "inputFolder = 'tblADataRTCGM_Unblinded_ControlGroup_1'\n",
    "patients = glob(inputFolder + '/*')\n",
    "outputFolder = inputFolder + '_output_' + str(PREDICTION_HORIZON)\n",
    "if not os.path.exists(outputFolder):\n",
    "    os.makedirs(outputFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tblADataRTCGM_Unblinded_ControlGroup_1/155.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/140.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/142.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/180.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/147.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/146.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/178.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/150.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/145.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/151.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/136.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/122.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/123.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/121.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/135.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/109.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/108.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/118.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/18.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/131.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/133.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/132.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/117.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/17.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/100.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/15.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/139.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/105.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/111.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/138.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/13.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/12.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/174.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/160.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/149.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/175.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/188.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/176.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/162.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/172.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/173.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/164.csv',\n",
       " 'tblADataRTCGM_Unblinded_ControlGroup_1/170.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data strategy\n",
    "Goal is to create data points consisting of a blood sugar measurement at a\n",
    " prediction time horizon of 30 mins, and measurements at the following times:\n",
    "   - Current time\n",
    "   - Current time - 10 mins\n",
    "   - Current time - 20 mins\n",
    "   - Current time - 30 mins\n",
    "   - Current time - 40 mins\n",
    "   - Current time - 60 mins\n",
    "   - Current time - 90 mins\n",
    "\n",
    " When the specified measurement time does not coincide with a measurement,\n",
    " the blood sugar level at the specified time will be determined by linear\n",
    " interpolation of the two nearest measurement points.\n",
    "\n",
    " Data points that represent potentially dangerous sugar lows or highs will be\n",
    " flagged for use in validation.\n",
    "\n",
    " Measurement points will only be used if they meet the following criteria:\n",
    "   - Values determined from linear interpolation must be determined from\n",
    "       measurements separated by no more than 11 mins\n",
    "   - All values must be taken from between the hours of 11pm and 7am. In other\n",
    "       words, the first prediction time considered will be ~1am.\n",
    "\n",
    "\n",
    " Performs a linear interpolation of the blood sugar measurements between two\n",
    " input data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(prev, cur, desiredTime) :\n",
    "    totalTime = (cur[0] - prev[0]).total_seconds()\n",
    "    prevToDesiredTime = (desiredTime - prev[0]).total_seconds()\n",
    "    # Perform linear interpolation:\n",
    "    sugar = prevPoint[1] + (((curPoint[1] - prevPoint[1]) / totalTime) * prevToDesiredTime)\n",
    "    return sugar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patientFolder in patients :\n",
    "    patientID = re.split(\"/\", patientFolder)[1][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/blaze/OneDrive/Work/HealthCare/Project 9 -- Deep Learning RNN for Predicting  Glucose Concentration for Diabetes1 Patients'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'170.csv'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(\"/\", patientFolder)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'newline' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-8852dd9580d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tblADataRTCGM_Unblinded_ControlGroup_1/155.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'newline' is an invalid keyword argument for this function"
     ]
    }
   ],
   "source": [
    "open('tblADataRTCGM_Unblinded_ControlGroup_1/155.csv', newline='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input file\n",
    "for patientFolder in patients :\n",
    "    patientID = re.split(\"/\", patientFolder)[1][:-4]\n",
    "    outputTrainFile = outputFolder + '/' + patientID + '_train.csv'\n",
    "    outputTestFile = outputFolder + '/' + patientID + '_test.csv'\n",
    "    open(outputTrainFile, 'w').close()\n",
    "    open(outputTestFile, 'w').close()\n",
    "    days = glob(patientFolder + '/*')\n",
    "    for dayFile in days :\n",
    "        # Create new empty lists\n",
    "        data = []\n",
    "        processedData_Train = []\n",
    "        processedData_Test = []\n",
    "        with open(dayFile, newline = '') as f:\n",
    "            reader = csv.reader(f)\n",
    "            # Populate the list with a full day worth of data\n",
    "            # (from 12 noon until 12 noon to ensure that the complete night is included)\n",
    "            for row in reader :\n",
    "                #curTime = dateutil.parser.parse(row[2]) # Parse date\n",
    "                #curTime = datetime.strptime(row[2], '%Y-%m-%d %H:%M:%S.%f') # Example date: \"2001-03-03 12:01:00.000000\"\n",
    "                #bloodSugar = float(row[3]) # Parse blood sugar\n",
    "                curTime = datetime.strptime(row[0], '%m\\%d\\%Y %H:%M')\n",
    "                bloodSugar = float(row[1])\n",
    "                newTuple = (curTime, bloodSugar)\n",
    "                data.append(newTuple)\n",
    "        # End with file\n",
    "\n",
    "        # Make sure data is sorted by time:\n",
    "        data.sort(key=lambda tup: tup[0])\n",
    "\n",
    "        # For each data point:\n",
    "        for index, predictionPoint in enumerate(data) :\n",
    "            valid = 1\n",
    "            # Only consider points between 1AM and 7AM:\n",
    "            if predictionPoint[0].hour >= 1 and predictionPoint[0].hour < 7 :\n",
    "                # Determine all desired measurement times:\n",
    "                time1 = predictionPoint[0] - timedelta(minutes = PREDICTION_HORIZON) # 30 mins ago\n",
    "                tenMinutes = timedelta(minutes = 10)\n",
    "                time2 = time1 - tenMinutes # 40 mins ago\n",
    "                time3 = time2 - tenMinutes # 50 mins ago\n",
    "                time4 = time3 - tenMinutes # 60 mins ago\n",
    "                time5 = time4 - tenMinutes # 70 mins ago\n",
    "                time6 = time5 - timedelta(minutes = 20) # 90 mins ago\n",
    "                time7 = time6 - timedelta(minutes = 30) # 120 mins ago\n",
    "\n",
    "                # Initialize all blood sugar measurements\n",
    "                bloodSugar1 = -1.0\n",
    "                bloodSugar2 = -1.0\n",
    "                bloodSugar3 = -1.0\n",
    "                bloodSugar4 = -1.0\n",
    "                bloodSugar5 = -1.0\n",
    "                bloodSugar6 = -1.0\n",
    "                bloodSugar7 = -1.0\n",
    "\n",
    "                curPoint = predictionPoint\n",
    "                # Iterate from current index backwards\n",
    "                for i in range(index - 1, -1, -1) :\n",
    "                    prevPoint = data[i]\n",
    "                    # If prevPoint and curPoint aren't too far apart\n",
    "                    if (prevPoint[0] + timedelta(minutes = 12)) > curPoint[0] :\n",
    "                        if prevPoint[0] <= time1 and curPoint[0] > time1 : # Straddling time1\n",
    "                            bloodSugar1 = interpolate(prevPoint, curPoint, time1)\n",
    "                        elif prevPoint[0] <= time2 and curPoint[0] > time2 : # Straddling time2\n",
    "                            bloodSugar2 = interpolate(prevPoint, curPoint, time2)\n",
    "                        elif prevPoint[0] <= time3 and curPoint[0] > time3 : # Straddling time3\n",
    "                            bloodSugar3 = interpolate(prevPoint, curPoint, time3)\n",
    "                        elif prevPoint[0] <= time4 and curPoint[0] > time4 : # Straddling time4\n",
    "                            bloodSugar4 = interpolate(prevPoint, curPoint, time4)\n",
    "                        elif prevPoint[0] <= time5 and curPoint[0] > time5 : # Straddling time5\n",
    "                            bloodSugar5 = interpolate(prevPoint, curPoint, time5)\n",
    "                        elif prevPoint[0] <= time6 and curPoint[0] > time6 : # Straddling time6\n",
    "                            bloodSugar6 = interpolate(prevPoint, curPoint, time6)\n",
    "                        elif prevPoint[0] <= time7 and curPoint[0] > time7 : # Straddling time7\n",
    "                            bloodSugar7 = interpolate(prevPoint, curPoint, time7)\n",
    "                    curPoint = prevPoint # Update curPoint for next iteration\n",
    "\n",
    "                # If all bloodSugar measuremets were determined:\n",
    "                if  (bloodSugar1 > 0) and (bloodSugar2 > 0) and (bloodSugar3 > 0) and (bloodSugar4 > 0) and (bloodSugar5 > 0) and (bloodSugar6 > 0) and (bloodSugar7 > 0) :\n",
    "                    newPoint = (bloodSugar7, bloodSugar6, bloodSugar5, bloodSugar4, bloodSugar3, bloodSugar2, bloodSugar1, predictionPoint[1])\n",
    "                    randNum = random.random() #Random float between 0 and 1\n",
    "                    if randNum > 0.25 :\n",
    "                        processedData_Train.append(newPoint) # Added to training set with probability of 75%\n",
    "                    else :\n",
    "                        processedData_Test.append(newPoint)\n",
    "            # End if predictionPoint is between 1AM and 7AM\n",
    "        # End for each input data predictionPoint\n",
    "\n",
    "        # Write results to output files:\n",
    "        # Ouput file contains blood sugar measurments with following format on each line:\n",
    "        # '90 mins ago','60 mins ago','40 mins ago','30 mins ago','20 mins ago','10 mins ago','cur time','30 mins ahead'\n",
    "        with open(outputTrainFile, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(processedData_Train)\n",
    "            print(processedData_Train)\n",
    "\n",
    "        with open(outputTestFile, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(processedData_Test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Feed Froward Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The network has 7 input nodes and 1 output node. If the current time is 'T',\n",
    " then the inputs and output represent the blood glucose measurements at the\n",
    " following times:\n",
    "   Inputs:     - T\n",
    "               - (T - 10 mins)\n",
    "               - (T - 20 mins)\n",
    "               - (T - 30 mins)\n",
    "               - (T - 40 mins)\n",
    "               - (T - 50 mins)\n",
    "               - (T - 60 mins)\n",
    "\n",
    "   Output:     - (T + 20 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "NUM_EPOCHS = 1500 # Number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readData reads data from the specified pre-processed input data file.\n",
    "# The function returns an array of input data points and an array of the\n",
    "# corresponding desired outputs.\n",
    "def readData(filePath) :\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    with open(filePath, 'r') as f:\n",
    "        for line in f:\n",
    "            values = line.split(',')\n",
    "            time1 = float(values[0])\n",
    "            time2 = float(values[1])\n",
    "            time3 = float(values[2])\n",
    "            time4 = float(values[3])\n",
    "            time5 = float(values[4])\n",
    "            time6 = float(values[5])\n",
    "            time7 = float(values[6])\n",
    "            time8 = float(values[7])\n",
    "            newPointx = [time1, time2, time3, time4, time5, time6, time7] # Input\n",
    "            newPointy = [time8] # Desired Output\n",
    "            x_data.append(newPointx)\n",
    "            y_data.append(newPointy)\n",
    "    data = [x_data, y_data]\n",
    "    return data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the evaluation metrics and the coresponding generating function\n",
    " evaluateNetwork runs the trained network on the the provided network and\n",
    " reports the following evaluation metrics:\n",
    "   - mean squared prediction error\n",
    "   - percentage of lows that were correctly identified\n",
    "   - percentage of highs that were corretly identified\n",
    "   - number of falsely reported lows\n",
    "   - number of falsely reported highs\n",
    "\n",
    " These metrics are defined as follows:\n",
    "   - MSE:\n",
    "       -> Average of (y_desired - y_actual)^2 for each test point\n",
    "   - Low prediction accuracy:\n",
    "       -> 100 * (Number of correct lows) / (Number of lows)\n",
    "       -> Lows are any blood glucose level less than 70 mg/dL\n",
    "   - High prediction accuracy:\n",
    "       -> 100 * (Number of correct highs) / (Number of highs)\n",
    "       -> Highs are any blood glucose level greater than 200\n",
    "   - Number of false lows:\n",
    "       -> Number of false lows where (y_desired - y_actual) > 6\n",
    "       -> Note: false alarms are not counted if the prediction error is small\n",
    "   - Number of false highs:\n",
    "       -> Number of false highs where (y_actual - y_desired) > 6\n",
    "       -> Note: false alarms are not counted if the prediciton error is small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateNetwork(session, inData, outData, prediction) :\n",
    "    # Compute mse:\n",
    "    mse = session.run(tf.reduce_mean(tf.square(prediction - y_desired)), feed_dict={x: inData, y_desired: outData})\n",
    "    numTestPoints = len(inData)\n",
    "    numPredictedLows = 0\n",
    "    numLows = 0\n",
    "    numFalseLows = 0\n",
    "    numPredictedHighs = 0\n",
    "    numHighs = 0\n",
    "    numFalseHighs = 0\n",
    "    for i, inputPoint in enumerate(inData) :\n",
    "        # Apply network on current point:\n",
    "        predicted = session.run(prediction, feed_dict={x: [inputPoint]})\n",
    "        desired = outData[i][0]\n",
    "\n",
    "\n",
    "        # Update numLows, numHighs:\n",
    "        if(desired < 70) :\n",
    "            numLows += 1\n",
    "        elif(desired > 200) :\n",
    "            numHighs += 1\n",
    "\n",
    "        # Update prediction counts:\n",
    "        if(predicted < 70) : # If predicted low\n",
    "            if(desired < 70) : # If low prediction was correct\n",
    "                numPredictedLows += 1\n",
    "            elif((desired - predicted) > 8) : # If low prediction was incorrect and error was 'large'\n",
    "                numFalseLows += 1\n",
    "        elif(predicted > 200) : # If predicted high\n",
    "            if(desired > 200) : # If high prediction was correct\n",
    "                numPredictedHighs += 1\n",
    "            elif((predicted - desired) > 8) : # If high prediction was incorrect and error was 'large'\n",
    "                numFalseHighs += 1\n",
    "    # Print results:\n",
    "    print('Number of test points: ', numTestPoints)\n",
    "    print('Number of lows: ', numLows)\n",
    "    print('Number of highs: ', numHighs)\n",
    "    print(\"Number of 'normal' points: \", numTestPoints - numLows - numHighs)\n",
    "    print('') # New line\n",
    "    print('MSE: ', mse)\n",
    "    print('')\n",
    "    print('Low prediction accuracy: ', 100 * numPredictedLows / numLows, '%')\n",
    "    print('Number of false lows: ', numFalseLows)\n",
    "    print('')\n",
    "    print('High prediction accuracy: ', 100 * numPredictedHighs / numHighs, '%')\n",
    "    print('Number of false highs: ', numFalseHighs)\n",
    "# End evaluateNetwork(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 7], name='x') # Input placeholder\n",
    "y_desired = tf.placeholder(tf.float32, [None, 1], name='y_desired') # Desired output placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'x_2:0' shape=(?, 7) dtype=float32>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedForwardNN(x) :\n",
    "    # Define the weights from inputs to first hidden layer (15 nodes):\n",
    "    Wh1 = tf.Variable(tf.random_uniform([7, 15], minval = -1, maxval = 1, dtype = tf.float32))\n",
    "    # Bias for first hidden layer:\n",
    "    bh1 = tf.Variable(tf.zeros([1, 15]))\n",
    "\n",
    "    # Define the weights from first hidden layer to second (15 nodes):\n",
    "    Wh2 = tf.Variable(tf.random_uniform([15, 15], minval = -1, maxval = 1, dtype = tf.float32)) # The weights from each of the 784 inputs to the 10 output nodes\n",
    "    # Bias for second hidden layer:\n",
    "    bh2 = tf.Variable(tf.zeros([1, 15])) # One bias input for each of the 10 output nodes\n",
    "\n",
    "    # Define the weights from second hidden layer to output layer (1 node):\n",
    "    Wo = tf.Variable(tf.random_uniform([15, 1], minval = -1, maxval = 1, dtype = tf.float32))\n",
    "    # Bias to output node:\n",
    "    bo = tf.Variable(tf.zeros([1, 1]))\n",
    "\n",
    "    # Generate the FFNN network\n",
    "    h1 = tf.add(tf.matmul(x, Wh1), bh1) # Hidden layer 1 output\n",
    "    h2 = tf.add(tf.matmul(h1, Wh2), bh2) # Hidden layer 2 output\n",
    "    output = tf.add(tf.matmul(h2, Wo), bo) # Network output\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Proessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainFFNN(x):\n",
    "    # Import the training data and test data:\n",
    "    # 151, 149, 174\n",
    "    trainData_in, trainData_out = readData('tblADataRTCGM_Unblinded_ControlGroup_1_output_20/174_train.csv')\n",
    "    testData_in, testData_out = readData('tblADataRTCGM_Unblinded_ControlGroup_1_output_20/174_test.csv')\n",
    "\n",
    "    prediction = feedForwardNN(x)\n",
    "\n",
    "    # Error function to be minimized is the mean square error:\n",
    "    loss = tf.reduce_mean(tf.square(prediction - y_desired))\n",
    "\n",
    "    # Define training algorithm (Adam Optimizer):\n",
    "    # Note: AdamOptimizer produced better results than the GradientDescentOptimizer\n",
    "    #train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "    # Train:\n",
    "    errors = []\n",
    "    sess = tf.InteractiveSession()\n",
    "    #tf.global_variables_initializer\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    for i in range(NUM_EPOCHS): # 1000 training epochs\n",
    "        ### Batch training was tested, but per-epoch produced better results:\n",
    "        # Train with one batch at a time:\n",
    "        #for start, end in zip(range(0, len(trainData_in), BATCH_SIZE), range(BATCH_SIZE, len(trainData_in), BATCH_SIZE)):\n",
    "            #sess.run(train_step, feed_dict={x: trainData_in[start:end], y_desired: trainData_out[start:end]})\n",
    "\n",
    "        # Per-Epoch training:\n",
    "        sess.run(init, feed_dict={x: trainData_in, y_desired: trainData_out})\n",
    "        # Print MSE on test data after every 10 epochs\n",
    "        if i % 10 == 0:\n",
    "            mse = sess.run(tf.reduce_mean(tf.square(prediction - y_desired)), feed_dict={x: testData_in, y_desired: testData_out})\n",
    "            errors.append(mse)\n",
    "            print(mse)\n",
    "\n",
    "    # Output the desired and actual outputs for each test data point\n",
    "    #for i, inputPoint in enumerate(testData_in) :\n",
    "    #    output = sess.run(y, feed_dict={x: [inputPoint]})\n",
    "    #    print('desired: ', testData_out[i], ', actual: ', output)\n",
    "\n",
    "    # Test:\n",
    "    print('Patient 174 data:')\n",
    "    evaluateNetwork(sess, testData_in, testData_out, prediction)\n",
    "    print('Patient 149 data:')\n",
    "    testData_in, testData_out = readData('tblADataRTCGM_Unblinded_ControlGroup_1_output_20/149_test.csv')\n",
    "    evaluateNetwork(sess, testData_in, testData_out, prediction)\n",
    "    print('Patient 151 data:')\n",
    "    testData_in, testData_out = readData('tblADataRTCGM_Unblinded_ControlGroup_1_output_20/151_test.csv')\n",
    "    evaluateNetwork(sess, testData_in, testData_out, prediction)\n",
    "    # Uncomment this to evaluate the current network on a different patient:\n",
    "    #testData_in, testData_out = readData('tblADataRTCGM_Blind_Baseline_Split_output/78_test.csv')\n",
    "    #evaluateNetwork(sess, testData_in, testData_out, prediciton)\n",
    "\n",
    "    # Plot the MSE throughout training\n",
    "    #plt.plot(errors)\n",
    "    #plt.xlabel('#epochs')\n",
    "    #plt.ylabel('MSE')\n",
    "    #plt.show()\n",
    "# End trainFFNN(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to train and evalue the performance of the our FFNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3143655.2\n",
      "2098803.0\n",
      "163402.73\n",
      "1436603.4\n",
      "597857.6\n",
      "1265184.8\n",
      "894934.8\n",
      "4017109.8\n",
      "2873486.0\n",
      "2341409.5\n",
      "679770.0\n",
      "16535.791\n",
      "2819171.8\n",
      "2678143.5\n",
      "3277605.8\n",
      "1177102.9\n",
      "573267.44\n",
      "202795.06\n",
      "1858651.9\n",
      "257663.44\n",
      "72567.164\n",
      "231765.58\n",
      "37563.91\n",
      "1423949.9\n",
      "397625.88\n",
      "3952893.2\n",
      "370551.25\n",
      "877712.0\n",
      "248722.77\n",
      "649146.4\n",
      "597026.94\n",
      "28260.71\n",
      "5383620.5\n",
      "3956015.5\n",
      "2826423.2\n",
      "690672.1\n",
      "3432848.8\n",
      "5066525.5\n",
      "1783709.2\n",
      "538851.44\n",
      "289013.94\n",
      "2845549.5\n",
      "6499.5503\n",
      "325148.38\n",
      "3782.4075\n",
      "43190.82\n",
      "230467.16\n",
      "3503061.2\n",
      "249861.84\n",
      "26292.014\n",
      "1198333.8\n",
      "956550.3\n",
      "8715.05\n",
      "37621.184\n",
      "640085.8\n",
      "1171535.8\n",
      "1816937.1\n",
      "160295.88\n",
      "128779.27\n",
      "201975.56\n",
      "59716.734\n",
      "683425.06\n",
      "458186.34\n",
      "595263.2\n",
      "7590.816\n",
      "240371.77\n",
      "3093866.5\n",
      "2741090.8\n",
      "1834089.4\n",
      "343981.06\n",
      "935493.1\n",
      "2911213.5\n",
      "27815.96\n",
      "205144.81\n",
      "90585.95\n",
      "25290.451\n",
      "3035599.2\n",
      "3467593.2\n",
      "639696.3\n",
      "3203.5386\n",
      "2882804.5\n",
      "419494.1\n",
      "1876406.2\n",
      "4910376.0\n",
      "120485.27\n",
      "742360.3\n",
      "280217.38\n",
      "1460133.5\n",
      "1555506.8\n",
      "1803263.5\n",
      "1383842.6\n",
      "1173347.6\n",
      "3589.295\n",
      "717553.75\n",
      "9478921.0\n",
      "303569.6\n",
      "2187126.8\n",
      "8764990.0\n",
      "1036579.06\n",
      "1228194.2\n",
      "366389.44\n",
      "4796006.0\n",
      "1379830.4\n",
      "4921271.0\n",
      "43949.086\n",
      "961903.56\n",
      "351114.1\n",
      "3136724.5\n",
      "1962475.8\n",
      "134985.75\n",
      "562.08203\n",
      "4050961.5\n",
      "1855.3451\n",
      "88008.305\n",
      "324464.47\n",
      "8401456.0\n",
      "40200.613\n",
      "2393962.2\n",
      "4574322.0\n",
      "2637122.0\n",
      "61099.336\n",
      "1059410.2\n",
      "3396028.2\n",
      "202289.6\n",
      "1602147.5\n",
      "7699542.5\n",
      "161617.73\n",
      "2513607.2\n",
      "6761300.5\n",
      "261375.6\n",
      "1780208.4\n",
      "4906324.5\n",
      "8571115.0\n",
      "8903210.0\n",
      "379633.47\n",
      "619649.44\n",
      "216801.52\n",
      "309007.8\n",
      "774929.94\n",
      "172359.89\n",
      "2711291.5\n",
      "37099.902\n",
      "1096820.5\n",
      "1610736.4\n",
      "2141615.2\n",
      "239419.14\n",
      "126292.65\n",
      "86326.79\n",
      "2614208.0\n",
      "66590.19\n",
      "Patient 174 data:\n",
      "Number of test points:  1441\n",
      "Number of lows:  6\n",
      "Number of highs:  257\n",
      "Number of 'normal' points:  1178\n",
      "\n",
      "MSE:  186803.73\n",
      "\n",
      "Low prediction accuracy:  100.0 %\n",
      "Number of false lows:  1431\n",
      "\n",
      "High prediction accuracy:  0.0 %\n",
      "Number of false highs:  0\n",
      "Patient 149 data:\n",
      "Number of test points:  2379\n",
      "Number of lows:  61\n",
      "Number of highs:  807\n",
      "Number of 'normal' points:  1511\n",
      "\n",
      "MSE:  244347.9\n",
      "\n",
      "Low prediction accuracy:  100.0 %\n",
      "Number of false lows:  2303\n",
      "\n",
      "High prediction accuracy:  0.247831474597 %\n",
      "Number of false highs:  0\n",
      "Patient 151 data:\n",
      "Number of test points:  1525\n",
      "Number of lows:  99\n",
      "Number of highs:  80\n",
      "Number of 'normal' points:  1346\n",
      "\n",
      "MSE:  134368.89\n",
      "\n",
      "Low prediction accuracy:  98.9898989899 %\n",
      "Number of false lows:  1419\n",
      "\n",
      "High prediction accuracy:  0.0 %\n",
      "Number of false highs:  0\n"
     ]
    }
   ],
   "source": [
    "trainFFNN(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value beta2_power_16\n\t [[Node: beta2_power_16/read = Identity[T=DT_FLOAT, _class=[\"loc:@Variable_100\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](beta2_power_16)]]\n\nCaused by op u'beta2_power_16/read', defined at:\n  File \"/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 1064, in start\n    handler_func(fd_obj, events)\n  File \"/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2824, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-86-2f5e15240656>\", line 1, in <module>\n    trainFFNN(x)\n  File \"<ipython-input-85-6b8470d61182>\", line 15, in trainFFNN\n    train_step = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 410, in minimize\n    name=name)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 588, in apply_gradients\n    self._create_slots(var_list)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/adam.py\", line 130, in _create_slots\n    colocate_with=first_var)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 809, in _create_non_slot_variable\n    v = variable_scope.variable(initial_value, name=name, trainable=False)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2443, in variable\n    aggregation=aggregation)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2425, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2406, in default_variable_creator\n    constraint=constraint)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 259, in __init__\n    constraint=constraint)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 422, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 80, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3264, in identity\n    \"Identity\", input=input, name=name)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value beta2_power_16\n\t [[Node: beta2_power_16/read = Identity[T=DT_FLOAT, _class=[\"loc:@Variable_100\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](beta2_power_16)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-2f5e15240656>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainFFNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-85-6b8470d61182>\u001b[0m in \u001b[0;36mtrainFFNN\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Per-Epoch training:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainData_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_desired\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainData_out\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Print MSE on test data after every 10 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value beta2_power_16\n\t [[Node: beta2_power_16/read = Identity[T=DT_FLOAT, _class=[\"loc:@Variable_100\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](beta2_power_16)]]\n\nCaused by op u'beta2_power_16/read', defined at:\n  File \"/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 1064, in start\n    handler_func(fd_obj, events)\n  File \"/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2824, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-86-2f5e15240656>\", line 1, in <module>\n    trainFFNN(x)\n  File \"<ipython-input-85-6b8470d61182>\", line 15, in trainFFNN\n    train_step = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 410, in minimize\n    name=name)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 588, in apply_gradients\n    self._create_slots(var_list)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/adam.py\", line 130, in _create_slots\n    colocate_with=first_var)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 809, in _create_non_slot_variable\n    v = variable_scope.variable(initial_value, name=name, trainable=False)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2443, in variable\n    aggregation=aggregation)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2425, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2406, in default_variable_creator\n    constraint=constraint)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 259, in __init__\n    constraint=constraint)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 422, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 80, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3264, in identity\n    \"Identity\", input=input, name=name)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value beta2_power_16\n\t [[Node: beta2_power_16/read = Identity[T=DT_FLOAT, _class=[\"loc:@Variable_100\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](beta2_power_16)]]\n"
     ]
    }
   ],
   "source": [
    "trainFFNN(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
